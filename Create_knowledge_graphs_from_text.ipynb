{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "w1phfQ-hy6e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfk0MsxPy4z0"
      },
      "outputs": [],
      "source": [
        "import wikipedia as wp\n",
        "import re\n",
        "import requests\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "import networkx as nx\n",
        "from pyvis.network import Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Data"
      ],
      "metadata": {
        "id": "xdpy9NoMy-NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the language of the response\n",
        "wp.set_lang(\"en\")\n",
        "\n",
        "# Obtain and store the data\n",
        "title = \" 'New York City' \"\n",
        "data = wp.page(title).content\n",
        "\n",
        "# View the data\n",
        "print(data)"
      ],
      "metadata": {
        "id": "gC4Y1Aony-As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Data"
      ],
      "metadata": {
        "id": "oZFk3PnSzC6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to lowercase and replace new lines\n",
        "data = data.lower().replace('\\n', \"\")\n",
        "\n",
        "# Remove the last part of the text, certain punctuation marks, headings, as well as any text within the parentheses\n",
        "data = re.sub('== see also ==.*|[@#:&\\\"]|===.*?===|==.*?==|\\(.*?\\)', '', data)\n",
        "\n",
        "# View the data\n",
        "print(data)"
      ],
      "metadata": {
        "id": "0IMA2PgtzCwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognize Named Entities"
      ],
      "metadata": {
        "id": "wLAryFOlzHC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a language model\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "doc=nlp(data)\n",
        "\n",
        "# Display the entities in the doc\n",
        "displacy.render(doc,style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "id": "NibxpUFTzJC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Coreference Clusters"
      ],
      "metadata": {
        "id": "VMMfLDB9zKs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the coreference resolution component in the pipeline\n",
        "nlp.add_pipe('coreferee')\n",
        "\n",
        "# Pass the data to the language model\n",
        "doc = nlp(data)\n",
        "\n",
        "# Print resolved coreferences, if any\n",
        "doc._.coref_chains.print()"
      ],
      "metadata": {
        "id": "yxCkFHpKzKeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resolve Coreferences"
      ],
      "metadata": {
        "id": "oRDTcX7MzO3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolved_data = \"\"\n",
        "for token in doc:\n",
        "    resolved_coref = doc._.coref_chains.resolve(token)\n",
        "    if resolved_coref:\n",
        "        resolved_data += \" \" + \" and \".join(r.text for r in resolved_coref)\n",
        "    elif token.dep_ == \"punct\":\n",
        "        resolved_data += token.text\n",
        "    else:\n",
        "        resolved_data += \" \" + token.text"
      ],
      "metadata": {
        "id": "aeLfMws-zOgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Relationships"
      ],
      "metadata": {
        "id": "7lpyJi6azOUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relationship(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    first, last = None, None\n",
        "\n",
        "    for chunk in doc.noun_chunks:\n",
        "        if not first:\n",
        "            first = chunk\n",
        "        else:\n",
        "            last = chunk\n",
        "\n",
        "    if first and last:\n",
        "        return (first.text.strip(), last.text.strip(), str(doc[first.end:last.start]).strip())\n",
        "\n",
        "    return (None, None, None)"
      ],
      "metadata": {
        "id": "xcYB7sRBzV1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Graph"
      ],
      "metadata": {
        "id": "iUDXyaEczXiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A helper function that prints 5 words per row. Can be used for better readability of a given text.\n",
        "print_five_words = lambda sentence: '\\n'.join(' '.join(sentence.split()[i:i+5]) for i in range(0, len(sentence.split()), 5))"
      ],
      "metadata": {
        "id": "gwnIRRj0zZVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Network object\n",
        "graph_doc = nlp(resolved_data)\n",
        "\n",
        "# Create an empty graph\n",
        "nx_graph = nx.DiGraph()\n",
        "\n",
        "for sent in enumerate(graph_doc.sents) :\n",
        "    if len(sent[1]) > 3:\n",
        "        (a, b, c) = extract_relationship(str(sent[1]))\n",
        "\n",
        "        # Add nodes and edges to graph\n",
        "        if a and b:\n",
        "            nx_graph.add_node(a, size = 5)\n",
        "            nx_graph.add_node(b, size = 5)\n",
        "            nx_graph.add_edge(a, b, weight=1, title=print_five_words(c), arrows=\"to\")\n",
        "\n",
        "g = Network(notebook=True, cdn_resources='in_line')\n",
        "g.from_nx(nx_graph)\n",
        "g.show(\"example.html\")"
      ],
      "metadata": {
        "id": "L50XgsGQzbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the Related Entities"
      ],
      "metadata": {
        "id": "bPeNL8svzdNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nx_graph.edges(['manhattan']))"
      ],
      "metadata": {
        "id": "4OmJGeSEzfI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}